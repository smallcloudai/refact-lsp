import json
import os
import asyncio
import traceback
import numpy as np

from argparse import ArgumentParser

from swe.utils import AgentRunner
from swe.utils import get_swe_bench_lite_instance
from swe.steps import ExploreRepoStep, Locate
from swe.utils.common import patched_file
from swe.utils.common import filename_mentioned

from pathlib import Path
from typing import Dict, Any, Tuple


# MODEL = "gpt-4o"
MODEL = "gpt-4o-mini"


def softmax(x):
    exp_x = np.exp(x - np.max(x))
    return exp_x / exp_x.sum(axis=0)


def calculate_cross_entropy(true_filename: str, found_files_tochange: Dict[str, Dict[str, Any]]) -> float:
    v_filenames = sorted(found_files_tochange.keys())
    v_true_distribution = [0.0] * len(v_filenames)
    v_model_ratings = [found_files_tochange[fn]["RELEVANCY"] for fn in v_filenames]

    if not v_filenames:  # no files are generated by the model
        v_true_distribution = [1.0]
        v_model_ratings = [1e-5]  # Use a small value to avoid log(0)
    else:
        for i, fn in enumerate(v_filenames):
            if true_filename in fn:
                v_true_distribution[i] = 1.0
                break
        else:
            v_true_distribution.append(1.0)
            assert sum(v_model_ratings) > 0, "must have other ratings"
            v_model_ratings.append(0)

    v_true_distribution = np.array(v_true_distribution)
    v_model_ratings = np.array(v_model_ratings)

    v_probs = softmax(v_model_ratings)
    v_probs = np.clip(v_probs, 1e-10, 1.0)
    cross_entropy = - np.sum(v_true_distribution * np.log(v_probs))
    if cross_entropy == -0.0:
        cross_entropy = 0.0
    return cross_entropy


class StepOneOnlyRunner(AgentRunner):

    async def _steps(self, base_url: str, repo_path: Path, *args, **kwargs) -> Tuple[Dict[str, Any], str]:
        results: Dict[str, Any] = dict()
        problem_statement = kwargs["problem_statement"]
        true_filename: str = patched_file(kwargs["problem_patch"])
        results["patched_file"] = true_filename
        results["patched_file_mentioned_in_problem"] = filename_mentioned(true_filename, problem_statement)
        rf = Locate(base_url=base_url, model_name=MODEL, attempts=1)
        found_files: Dict[str, Dict[str, Any]]    # {"filename": {"prop1": value, "prop2": value}, ...}
        try:
            found_files, symbols = await rf.process(
                problem_statement=problem_statement,
                repo_path=repo_path)
        except Exception as e:
            raise e
            results["error"] = f"step1: {type(e)} {str(e) or traceback.format_exc()}"
            found_files = {}
        if isinstance(found_files, list):
            found_files_tochange = {d["file_path"]: d for d in found_files if d["reason"] == "to_change"}
            found_files_list = [d["file_path"] for d in found_files_tochange.values()]
            for d in found_files_tochange.values():
                d["RELEVANCY"] = 5
        else:
            found_files_tochange = {k: d for k, d in found_files.items() if d["WHY_CODE"] == "TOCHANGE"}
            found_files_list = list(found_files_tochange.keys())
        results["found_files"] = found_files_list
        results["patched_file_is_found"] = filename_mentioned(true_filename, "\n".join(found_files_list))
        results["model_name"] = rf.model_name
        results["usage"] = rf.usage
        # def calculate_cross_entropy(true_filename: str, found_files_tochange: Dict[str, Dict[str, Any]]) -> float:
        results["cross_entropy"] = calculate_cross_entropy(true_filename, found_files_tochange)
        return results, rf.trajectory


async def main():
    parser = ArgumentParser()
    # django__django-11039
    parser.add_argument("instance_id", type=str, help="SWE instance id")
    parser.add_argument("--timeout", type=float, default=None, help="processing timeout")
    parser.add_argument("--output-dir", type=Path, required=True, help="output directory")
    args = parser.parse_args()
    args.output_dir.mkdir(exist_ok=True, parents=True)

    instance = get_swe_bench_lite_instance(args.instance_id)
    run_postfix = f"-{args.output_dir.name}" if args.output_dir is not None else ""
    results = {
        "model_name_or_path": f"refact-dev-{MODEL}{run_postfix}",
        "instance_id": args.instance_id,
        "problem_statement": instance["problem_statement"],
        "problem_patch": instance["patch"],
    }
    traj = ""

    try:
        runner = StepOneOnlyRunner(
            timeout=args.timeout,
            use_ast=True,
            use_vecdb=False,
        )
        r, traj = await runner.run(
            repo_name=instance["repo"],
            base_commit=instance["base_commit"],
            output_dir=args.output_dir,
            **results,
        )
        results.update(**r, **results)
    except Exception as e:
        raise e
        results["error"] = str(e) or traceback.format_exc()

    cross_entropy = results.get("cross_entropy", 9.0)
    lsp_log_fn = results["lsp_log_fn"]
    os.rename(lsp_log_fn, args.output_dir / ("%0.3f-%s-lsp.log" % (cross_entropy, args.instance_id)))
    with open(args.output_dir / ("%0.3f-%s.json" % (cross_entropy, args.instance_id)), "w") as f:
        json.dump(results, f, indent=4)
    with open(args.output_dir / ("%0.3f-%s.md" % (cross_entropy, args.instance_id)), "w") as f:
        f.write(traj)
    return results


if __name__ == "__main__":
    asyncio.run(main())
